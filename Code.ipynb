{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Obtaining dependency information for mediapipe from https://files.pythonhosted.org/packages/ee/ff/6f914bd788d2be5f22c47952804b0c8d68ef438a7c7fb80df6773866fa2e/mediapipe-0.10.3-cp311-cp311-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading mediapipe-0.10.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/chaitanyakota/Library/Python/3.11/lib/python/site-packages (from mediapipe) (22.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mediapipe) (1.24.2)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/9c/85/fcae5a3cf1ef35f6e4b7d9062d57b1f8312d9f35274f333f1aceb2b0bc50/opencv_contrib_python-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading opencv_contrib_python-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting protobuf<4,>=3.11 (from mediapipe)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Downloading sounddevice-0.4.6-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: CFFI>=1.0 in /Users/chaitanyakota/Library/Python/3.11/lib/python/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Users/chaitanyakota/Library/Python/3.11/lib/python/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Downloading mediapipe-0.10.3-cp311-cp311-macosx_11_0_universal2.whl (53.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_contrib_python-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl (41.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, opencv-contrib-python, sounddevice, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.3\n",
      "    Uninstalling protobuf-4.23.3:\n",
      "      Successfully uninstalled protobuf-4.23.3\n",
      "Successfully installed mediapipe-0.10.3 opencv-contrib-python-4.8.0.74 protobuf-3.20.3 sounddevice-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mediapipe as mp\n",
    "# Used to convert protobuf message to a dictionary.\n",
    "from google.protobuf.json_format import MessageToDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    max_num_hands=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "  \n",
    "while True:\n",
    "    # Read video frame by frame\n",
    "    success, img = cap.read()\n",
    "  \n",
    "    # Flip the image(frame)\n",
    "    img = cv2.flip(img, 1)\n",
    "  \n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  \n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    if results.multi_hand_landmarks:# If hands are present in image(frame)\n",
    "\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):# Loop through each detected hand\n",
    "            label = MessageToDict(results.multi_handedness[i])['classification'][0]['label']# Return whether it is Right or Left Hand\n",
    "\n",
    "            x_min, y_min, x_max, y_max = float('inf'), float('inf'), float('-inf'), float('-inf')# Draw bounding box around the hand\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y = int(landmark.x * img.shape[1]), int(landmark.y * img.shape[0])\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x)\n",
    "                y_max = max(y_max, y)\n",
    "            cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            \n",
    "            label_size = cv2.getTextSize(label + ' Hand', cv2.FONT_HERSHEY_COMPLEX, 0.9, 2)[0]\n",
    "            \n",
    "            if len(results.multi_handedness) == 2:\n",
    "                cv2.putText(img, 'Both Hands', (450, 250),# Display 'Both Hands' on the image\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                if label == 'Left':\n",
    "                    cv2.putText(img, label + ' Hand',\n",
    "                            (x_min, y_min - label_size[1]),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, \n",
    "                            0.9, (0, 255, 0), 2)\n",
    "                if label == 'Right':\n",
    "                    cv2.putText(img, label + ' Hand', (x_min, y_min - label_size[1]),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX,\n",
    "                            0.9, (0, 255, 0), 2)\n",
    "  \n",
    "\n",
    "    cv2.imshow('Video', img)# Display the image(frame)\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
